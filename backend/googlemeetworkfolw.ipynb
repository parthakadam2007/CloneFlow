{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5d2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI    \n",
    "from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ad7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir =Path.cwd() \n",
    "persist_directory = current_dir /'db'/ 'main_db'\n",
    "persist_directory=str(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1cf6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b11b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model=\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a113a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796eff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    \n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory,  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e6eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_store= Chroma(persist_directory=persist_directory,\n",
    "            embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f4c05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb429cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.1}, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e33c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic import EmailStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa6b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langraph application\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.pydantic_v1 import Field\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7ed5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant position in graph.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\",\"embedder\"]| None  = Field(\n",
    "        None,\n",
    "        description=\"Given a todo list  choose to route it to vectorstore(vector store has all information related to email,personal ingo ,phone number,ect), or embedder\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3676288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm_router = llm.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8050a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an expert at routing a user todo list choose to route it to vectorstore(vector store has all information related to email,personal ingo ,phone number,ect), or Non\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{summer_and_todolist}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f9f9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_router = route_prompt | structured_llm_router\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fddc4322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e517bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question asked by the user.\n",
    "        summer_and_todolist: summary and todo list of the google meet recording.\n",
    "        textToSpeech: text to speech of the google meet recording.\n",
    "        todolist: todolist\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "        embedder_status: status of the embedder.\n",
    "        \n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    textToSpeech: str\n",
    "    summer_and_todolist: str\n",
    "    embedder_status: str\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8443e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "429dbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    summer_and_todolist = state[\"summer_and_todolist\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(summer_and_todolist)\n",
    "    state[\"documents\"] = documents\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935108b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f7e49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "client = genai.Client(api_key=\"AIzaSyBVcVdaE1qCdpONTHd2LS-6Tcz3vu65zww\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "914d14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sst_text_to_speech(state:GraphState):\n",
    "    \"\"\"\n",
    "    Text to speech of the google meet recording.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, textToSpeech, that contains the text to speech of the google meet recording\n",
    "    \"\"\"\n",
    "    print(\"---TEXT TO SPEECH---\")\n",
    "    # audio_path = \n",
    "    myfile = client.files.upload(file=r\"C://Users//DELL//Desktop//CloneFlow//production//myrecording.m4a\")\n",
    "    \n",
    "    textToSpeech= client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=[\" Text to speech of  this audio clip  \", myfile]\n",
    " )\n",
    "    #  state[\"new_key\"] = \"Hello, I'm a new state value!\"\n",
    "\n",
    "    state[\"textToSpeech\"] = textToSpeech.text\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3e4f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summer_and_todolist_maker(state:GraphState):\n",
    "    \"\"\"\n",
    "    Summarize the textToSpeech and create a todo list.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, summer_and_todolist, that contains the todo list and the summery of the textToSpeech\n",
    "    \"\"\"\n",
    "    print(\"---TODO LIST---\")\n",
    "    \n",
    "    textToSpeech = state[\"textToSpeech\"]\n",
    "    \n",
    "    # Create a todo list\n",
    "    summer_and_todolist = llm.invoke(f\"Create a todo list and summery  from this text: {textToSpeech}\")\n",
    "    state[\"summer_and_todolist\"] = summer_and_todolist.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0f4ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(state:GraphState):\n",
    "    \"\"\"\n",
    "    Schedule the todo list.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, scheduler, that contains the scheduled status\n",
    "    \"\"\"\n",
    "    print(\"---SCHEDULER---\")\n",
    "    summer_and_todolist = state[\"summer_and_todolist\"]\n",
    "    \n",
    "    # Schedule the todo list\n",
    "    state[\"scheduler\"] = \"shaduled\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05be54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def requrieInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "058920e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def route_question(state:GraphState):\n",
    "    \"\"\"\n",
    "    Route question to vector store or scheduler.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    summer_and_todolist = state[\"summer_and_todolist\"]\n",
    "    source = question_router.invoke({\"summer_and_todolist\":summer_and_todolist})\n",
    "    if source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO VECTOR STORE---\")\n",
    "      \n",
    "        return \"vectorstore\"\n",
    "    elif source.datasource == \"scheduler\":\n",
    "        print(\"---ROUTE QUESTION TO EMBEDDER---\")\n",
    "        return \"scheduler\"\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f2133fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embedder(state:GraphState):\n",
    "    \"\"\"\n",
    "    Call the embedder that saves the todolist for later use.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): returns a string saying that the todolist is saved\n",
    "    \"\"\"\n",
    "    print(\"---EMBEDDER---\")\n",
    "    summer_and_todolist = state[\"summer_and_todolist\"]\n",
    "    try:\n",
    "        vector_store.add_documents([Document(page_content=summer_and_todolist.countent)])\n",
    "        \n",
    "        \n",
    "        return {\"embedderSate\":\"successfully saved embeddings\"}\n",
    "        \n",
    "    except Exception as e:\n",
    "         return {\"embedderSate\":\"Error saving embeddings\"}\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc1bd0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating flow\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9097b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a49d860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23957afee50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"sst_text_to_speech\", sst_text_to_speech)\n",
    "workflow.add_node(\"summer_and_todolist_maker\", summer_and_todolist_maker)\n",
    "workflow.add_node(\"scheduler\", scheduler)\n",
    "workflow.add_node(\"embedder\", embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "950e262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23957afee50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build graph\n",
    "\n",
    "\n",
    "workflow.add_edge(START,\"sst_text_to_speech\")\n",
    "workflow.add_edge(\"sst_text_to_speech\", \"summer_and_todolist_maker\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"summer_and_todolist_maker\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"scheduler\": \"scheduler\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    }    \n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"embedder\")\n",
    "workflow.add_edge(\"scheduler\", \"embedder\")\n",
    "\n",
    "workflow.add_edge(\"embedder\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2186569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2239f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9054bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run\n",
    "# inputs = {\n",
    "#     \"question\": \"What is agent?\"\n",
    "# }\n",
    "# for output in app.stream(inputs):\n",
    "#     for key, value in output.items():\n",
    "#         # Node\n",
    "#         pprint(f\"Node '{key}':\")\n",
    "#         # Optional: print full state at each node\n",
    "#         # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "#     pprint(\"\\n---\\n\")\n",
    "\n",
    "# # Final generation\n",
    "# pprint(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f324d79",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fae762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "771a36a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TEXT TO SPEECH---\n",
      "\"Node 'sst_text_to_speech':\"\n",
      "'\\n---\\n'\n",
      "---TODO LIST---\n",
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO VECTOR STORE---\n",
      "\"Node 'summer_and_todolist_maker':\"\n",
      "'\\n---\\n'\n",
      "---RETRIEVE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---EMBEDDER---\n",
      "\"Node 'embedder':\"\n",
      "'\\n---\\n'\n",
      "'No final assistant message found.'\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "all_states=[]\n",
    "\n",
    "inputs = {\"question\": \"What is agent?\"}\n",
    "final_message = None  # Keep track of final generation manually\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        \n",
    "        # If this is the generation node and has messages\n",
    "        if isinstance(value, dict) and \"messages\" in value:\n",
    "            final_message = value[\"messages\"][-1].content\n",
    "    all_states.append(value)\n",
    "    pprint(\"\\n---\\n\")\n",
    "    \n",
    "\n",
    "# Print final message if available\n",
    "if final_message:\n",
    "    pprint(\"Assistant: \" + final_message)\n",
    "else:\n",
    "    pprint(\"No final assistant message found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edd59fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello, how are you all?\\n'\n",
      " 'So today we are going to take this meeting to decide what to do in our '\n",
      " 'project.\\n'\n",
      " 'So our project name is Clone AI.\\n'\n",
      " 'So what this Clone AI does is that it creates an environment for the user to '\n",
      " 'increase his productivity.\\n'\n",
      " \"So the idea behind the clone was that you don't have to think before you \"\n",
      " 'write emails.\\n'\n",
      " 'You just have to see it and the email will be written for you.\\n'\n",
      " \"It doesn't only have the feature of email, but it also has feature of \"\n",
      " 'scheduling meetings, contacts, and many modes features.\\n'\n",
      " 'So what I would like to do is I would like you to send an email to about '\n",
      " 'what I just discussed.\\n'\n",
      " 'Thank you to all.')\n"
     ]
    }
   ],
   "source": [
    "pprint(all_states[0]['textToSpeech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1a67f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**Todo List:**\\n'\n",
      " '\\n'\n",
      " '* [ ] Send an email summarizing the Clone AI project meeting.  The email '\n",
      " 'should include:\\n'\n",
      " '    * Project name: Clone AI\\n'\n",
      " '    * Project goal: Increase user productivity\\n'\n",
      " '    * Key features: Email generation, meeting scheduling, contact '\n",
      " 'management, and other unspecified \"many modes features.\"\\n'\n",
      " '    * Core concept: Automating tasks (like email writing) to reduce '\n",
      " 'cognitive load.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '**Summary:**\\n'\n",
      " '\\n'\n",
      " 'A meeting was held to discuss the Clone AI project.  Clone AI aims to boost '\n",
      " 'user productivity by automating tasks such as email composition, meeting '\n",
      " 'scheduling, and contact management.  The core idea is to eliminate the need '\n",
      " 'for users to think through these tasks, allowing them to focus on other '\n",
      " 'aspects of their work.  The next step is to send out an email summarizing '\n",
      " \"the meeting's discussion.\")\n"
     ]
    }
   ],
   "source": [
    "pprint(all_states[1]['summer_and_todolist'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
