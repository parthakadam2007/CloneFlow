{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b588f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI    \n",
    "from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26530975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c79817",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir =Path.cwd() \n",
    "persist_directory = current_dir /'db'/ 'main_db'\n",
    "persist_directory=str(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94dbd7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d98e5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model=\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0578ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "vector_store= Chroma(persist_directory=persist_directory,\n",
    "            embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557a4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.1}, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22183711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic import EmailStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a50f5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langraph application\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.pydantic_v1 import Field\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3505181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78d1f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant position in graph.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\",\"embedder\"]| None  = Field(\n",
    "        None,\n",
    "        description=\"Given a todo list  choose to route it to vectorstore(vector store has all information related to email,personal ingo ,phone number,ect), or embedder\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b4fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm_router = llm.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "142b1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an expert at routing a user todo list choose to route it to vectorstore(vector store has all information related to email,personal ingo ,phone number,ect), or Non\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{summer_and_todolist}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3635ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87844d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11dad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question asked by the user.\n",
    "        summer_and_todolist: summary and todo list of the google meet recording.\n",
    "        textToSpeech: text to speech of the google meet recording.\n",
    "        todolist: todolist\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "        embedder_status: status of the embedder.\n",
    "        \n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    textToSpeech: str\n",
    "    summer_and_todolist: str\n",
    "    embedder_status: str\n",
    "    input :str\n",
    "    all_documents: List[str]\n",
    "    query_list:List[str]\n",
    "    output:str\n",
    "    extraction:List[dict]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2a5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66fe5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "client = genai.Client(api_key=\"AIzaSyBVcVdaE1qCdpONTHd2LS-6Tcz3vu65zww\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f63f2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sst_text_to_speech(state:GraphState):\n",
    "    \"\"\"\n",
    "    Text to speech of the google meet recording.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, textToSpeech, that contains the text to speech of the google meet recording\n",
    "    \"\"\"\n",
    "    print(\"---TEXT TO SPEECH---\")\n",
    "    # audio_path = \n",
    "    myfile = client.files.upload(file=r\"C://Users//DELL//Desktop//CloneFlow//production//myrecording.m4a\")\n",
    "    \n",
    "    textToSpeech= client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=[\" Text to speech of  this audio clip  \", myfile]\n",
    " )\n",
    "    #  state[\"new_key\"] = \"Hello, I'm a new state value!\"\n",
    "\n",
    "    state[\"textToSpeech\"] = textToSpeech.text\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86c779c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summer_and_todolist_maker(state:GraphState):\n",
    "    \"\"\"\n",
    "    Summarize the textToSpeech and create a todo list.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, summer_and_todolist, that contains the todo list and the summery of the textToSpeech\n",
    "    \"\"\"\n",
    "    print(\"---TODO LIST---\")\n",
    "    \n",
    "    textToSpeech = state[\"textToSpeech\"]\n",
    "    \n",
    "    # Create a todo list\n",
    "    summer_and_todolist = llm.invoke(f\"Create a todo list and summery  from this text: {textToSpeech}\")\n",
    "    state[\"summer_and_todolist\"] = summer_and_todolist.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2808834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(state:GraphState):\n",
    "    \"\"\"\n",
    "    Schedule the todo list.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, scheduler, that contains the scheduled status\n",
    "    \"\"\"\n",
    "    print(\"---SCHEDULER---\")\n",
    "    summer_and_todolist = state[\"summer_and_todolist\"]\n",
    "    \n",
    "    # Schedule the todo list\n",
    "    state[\"scheduler\"] = \"shaduled\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b83c6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state:GraphState):\n",
    "    \"\"\"\n",
    "    Route question to vector store or scheduler.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    summer_and_todolist = state[\"summer_and_todolist\"]\n",
    "    source = question_router.invoke({\"summer_and_todolist\":summer_and_todolist})\n",
    "    if source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO VECTOR STORE---\")\n",
    "      \n",
    "        return \"vectorstore\"\n",
    "    elif source.datasource == \"scheduler\":\n",
    "        print(\"---ROUTE QUESTION TO EMBEDDER---\")\n",
    "        return \"scheduler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "798e4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(state:GraphState):\n",
    "    '''\n",
    "    generate a final output combininig retrive documents and the retrive documnets\n",
    "    '''\n",
    "    print(\"---generator---\")\n",
    "    input= state[\"input\"]\n",
    "    all_documents = state[\"all_documents\"]\n",
    "    \n",
    "    \n",
    "    result = llm.invoke(f\"your task is to add details into the original text,Do not mention were you got the information formDo not mention were you got the information form.only provide details about the things menstioned,text{input},context:{all_documents}\")\n",
    "    output = result.content\n",
    "    print(\"output\",output)\n",
    "    state[\"output\"]=output\n",
    "    \n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68d1a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(state:GraphState):\n",
    "    \"\"\"\n",
    "    Extract the information from the text in json format\n",
    "    \"\"\"\n",
    "    print(\"---extractor---\")\n",
    "    output= state[\"output\"]\n",
    "    print(\"output\",output)\n",
    "    promt = 'You are an email information extractor, will be given a text, you have to extract the information in format: [{\"email\":\"examplename@exaple.com\",\"body\":\"body of mail\",\"subject\":\"subject of the mail\"},{\"email\":\"examplename@exaple.com\",\"body\":\"body of mail\",\"subject\":\"subject of the mail\"}],do not give nay other thing other than the json string,if not found any email in the text, return json[{\"nothing found\":\"no email found\"}],text'\n",
    "    result = llm.invoke(f\"{promt}, text{output}\")\n",
    "    output = result.content\n",
    "    raw_output = output \n",
    "    print(\"raw_output\",raw_output)\n",
    "\n",
    "# Optional: remove prefix like \"json\" or anything before the actual JSON array\n",
    "    match = re.search(r'\\[.*\\]', raw_output, re.DOTALL)\n",
    "    queries = []\n",
    "    if match:\n",
    "     cleaned_json_str = match.group(0)\n",
    "     queries = json.loads(cleaned_json_str)\n",
    "     print(\"--->\",queries)\n",
    "    else:\n",
    "     print(\"No valid JSON array found in the output.\")\n",
    "\n",
    "    print(\"extraction\",queries)\n",
    "    state['extraction']=queries\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1d35cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating flow\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7323fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f5f46d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generating_qureys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33mgenerating_qureys\u001b[39m\u001b[33m\"\u001b[39m,\u001b[43mgenerating_qureys\u001b[49m)\n\u001b[32m      2\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33mmulti_query_retrival\u001b[39m\u001b[33m\"\u001b[39m,multi_query_retrival)\n\u001b[32m      3\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33mgenerator\u001b[39m\u001b[33m\"\u001b[39m,generator)\n",
      "\u001b[31mNameError\u001b[39m: name 'generating_qureys' is not defined"
     ]
    }
   ],
   "source": [
    "workflow.add_node(\"generating_qureys\",generating_qureys)\n",
    "workflow.add_node(\"multi_query_retrival\",multi_query_retrival)\n",
    "workflow.add_node(\"generator\",generator)\n",
    "workflow.add_node(\"extractor\",extractor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
