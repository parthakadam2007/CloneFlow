{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9e712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from pathlib import Path\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredExcelLoader, Docx2txtLoader\n",
    "\n",
    "import pickle\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2afe59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir =Path.cwd() \n",
    "persist_directory = current_dir /'db'/ 'main_db'\n",
    "persist_directory=str(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68553b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model=\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "900493c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    \n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory,  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fdced27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b9c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upload_Embeddings():\n",
    "    \"\"\"Function to process files from the 'uploads' directory and store embeddings.\"\"\"\n",
    "    \n",
    "    # Define paths\n",
    "\n",
    "    uploads_path = current_dir / 'uploads'\n",
    "    \n",
    "    print(\"Current Directory:\", current_dir)\n",
    "\n",
    "\n",
    "    # Get all files in the uploads directory\n",
    "    files = list(uploads_path.glob(\"*\"))  # ✅ More robust than os.listdir()\n",
    "\n",
    "    for f in files:\n",
    "        \n",
    "            ext = f.suffix.lower().lstrip('.')  # ✅ Get file extension safely\n",
    "\n",
    "            # Load document based on file type\n",
    "            if ext == 'txt':\n",
    "                print(f'{f.name} ---> is a txt')\n",
    "                loader = TextLoader(str(f))\n",
    "            elif ext == 'pdf':\n",
    "                print(f'{f.name} ---> is a pdf')\n",
    "                loader = PyPDFLoader(str(f))\n",
    "            elif ext == 'docx':\n",
    "                print(f'{f.name} ---> is a docx')\n",
    "                loader = Docx2txtLoader(str(f))\n",
    "            elif ext == 'xlsx':\n",
    "                print(f'{f.name} ---> is an xlsx')\n",
    "                loader = UnstructuredExcelLoader(str(f))\n",
    "            else:\n",
    "                print(f'{f.name} ---> skipped')\n",
    "                continue  \n",
    "\n",
    "            document = loader.load()\n",
    "         \n",
    "\n",
    "            # Split the document into chunks\n",
    "            text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "            docs = text_splitter.split_documents(document)\n",
    "\n",
    "            if not docs:\n",
    "                print(f\"Split into {len(docs)} chunks, so skipped\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Split into {len(docs)} chunks\")\n",
    "\n",
    "            # Generate embeddings and store in Chroma\n",
    "            embeddings = VertexAIEmbeddings(model=\"text-embedding-004\")\n",
    "            vector_store= Chroma.from_documents(docs, embeddings, persist_directory=str(persist_directory))\n",
    "            \n",
    "   \n",
    "                \n",
    "            print(f'Done with embeddings for {f}')\n",
    "       \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adef1b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\Users\\DELL\\Desktop\\CloneFlow\\backend\n",
      "2501.10893v1.pdf ---> is a pdf\n",
      "Split into 53 chunks\n",
      "Done with embeddings for c:\\Users\\DELL\\Desktop\\CloneFlow\\backend\\uploads\\2501.10893v1.pdf\n",
      "Lab exercise-III_ GP II_ Body Language effectivity in the Professional world_ Conduct methodology and Design of exercise.pdf ---> is a pdf\n",
      "Split into 3 chunks\n",
      "Done with embeddings for c:\\Users\\DELL\\Desktop\\CloneFlow\\backend\\uploads\\Lab exercise-III_ GP II_ Body Language effectivity in the Professional world_ Conduct methodology and Design of exercise.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "upload_Embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14f04ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='70fcd777-56a2-430b-a4b4-9da943b4f905', metadata={'author': '', 'creationdate': '', 'creator': 'LaTeX with hyperref', 'keywords': '', 'page': 16, 'page_label': '17', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\backend\\\\uploads\\\\2501.10893v1.pdf', 'subject': '', 'title': '', 'total_pages': 53, 'trapped': '/False'}, page_content='Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments\\ninstructions when the exact version for the target environment is not available. Concretely, we use\\nthe following sources for WebArena:\\n• https://docs.gitlab.com/ee/tutorials/\\n• https://support.google.com/maps\\n• https://www.amazon.com/hz/contact-us/foresight/hubgateway\\n• https://support.reddithelp.com/hc/en-us/articles\\nThe following sources are used for OSWorld:\\n• https://support.google.com/chrome/?hl=en\\n• https://www.gimp.org/tutorials/\\n• https://books.libreoffice.org/en/CG72/CG72.html\\n• https://books.libreoffice.org/en/WG73/WG73.html\\n• https://ubuntu.com/tutorials/command-line-for-beginners\\n• https://support.mozilla.org/en-US/products/thunderbird\\n• https://wiki.videolan.org/Documentation:Documentation\\n• https://code.visualstudio.com/docs\\n, The following sources are used for Spider2-V:\\n• https://docs.getdbt.com/\\n• https://release-1-7-2.dagster.dagster-docs.io/\\n• https://docs.astronomer.io/\\n• https://docs.airbyte.com/\\n• https://airbyte.com/tutorials/\\n• https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html\\n• https://superset.apache.org/docs/\\n• https://www.metabase.com/docs/v0.49/\\n• https://www.metabase.com/learn/\\n• https://docs.snowflake.com/en/\\n• https://cloud.google.com/bigquery/docs/\\n• https://jupyterlab.readthedocs.io/en/4.1.x/\\nE Synthesized data examples\\nFrom Table 20 to 26, we provide a complete example of data synthesis. To begin with, an LLM\\ngenerates instructions based on standard resources like tutorials, documentations and FAQs: Upload\\nCSV data in Google Drive to BigQuery. (See prompt in Table 29) It then attempts solve the task by\\npredicting actions and collecting feedback from environments (interactions). This produces a long\\ntrajectory showing how LLMs try to achieve the goal.\\nHowever, it is not guaranteed that the trajectory successfully achieves the target. In our example,\\nthe LLM makes a wrong prediction in the action 4. It selects the table source Google Cloud Storage,\\nwhile the correct action should select “Drive\" to align with the instruction that reuiqres to upload CSV\\ndata in Google Drive. This results in wrong actions in the subsequent predictions, and the generated\\ntrajectory is not aligned with the initial instruction, which leads to noisy data in this case.\\n17'), Document(id='ac5b8ee1-02b7-42e0-b9ca-ada9147a1068', metadata={'author': '', 'creationdate': '', 'creator': 'LaTeX with hyperref', 'keywords': '', 'page': 38, 'page_label': '39', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\backend\\\\uploads\\\\2501.10893v1.pdf', 'subject': '', 'title': '', 'total_pages': 53, 'trapped': '/False'}, page_content='Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments\\nsub-trajectory type instruction\\nObservation 8 Replicate the following: We are in the the interface for creating\\n↓ a table in Google Cloud’s BigQuery service. The page is divided\\nAction 9 into several sections. At the top, it indicates the user is creating\\n↓ a table from a Google Cloud Storage source, with a CSV file\\nObservation 9 Replicate trajectoryselected. The destination section shows the project ID and allows\\n↓ input for the dataset and table name. The destination table is\\nAction 10 empty. The table type is set to “Native table\". At the bottom,\\n↓ there’s an option for schema detection, with buttons to create the\\nObservation 10 table or cancel the operation. The left side of the screen displays a\\nnavigation menu for the Google Cloud Console, including options\\nlike Explorer and various project-related items. The overall layout\\nsuggests this is part of a larger cloud data management and\\nanalysis platform. After we click on the text box Table, we select\\nand focus on the text box. We then type “test\" into the box, which\\ngives the table a name. Except the textbox we are working on,\\nthe other parts of the webpage has not changed after clicking\\nand typing.\\nObservation 0\\n↓\\nAction 1\\n↓\\nObservation 1 New task Link CSV file in Google Cloud Storage to BigQuery\\n↓\\nAction 2\\n↓\\n......\\n↓\\nObservation 13\\nTable 28|Instructions generated from trajectory from Table 20 to 26\\n{Documentation}\\nBased on the tutorial, examplify 3 tasks that users frequently perform.\\nUser the following format to output:\\n...\\n...\\nTable 29|self-instruct prompts to propose instructions based on tutorials, documentations and FAQs.\\n39'), Document(id='666e8633-40dc-4ab1-87eb-eaa77d1ebd30', metadata={'author': '', 'creationdate': '', 'creator': 'LaTeX with hyperref', 'keywords': '', 'page': 13, 'page_label': '14', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\backend\\\\uploads\\\\2501.10893v1.pdf', 'subject': '', 'title': '', 'total_pages': 53, 'trapped': '/False'}, page_content='Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments\\nJ. Y. Koh, R. Lo, L. Jang, V. Duvvur, M. C. Lim, P.-Y. Huang, G. Neubig, S. Zhou, R. Salakhutdinov,\\nand D. Fried. Visualwebarena: Evaluating multimodal agents on realistic visual web tasks.arXiv\\ne-prints, pages arXiv–2401, 2024.\\nY. Li, J. He, X. Zhou, Y. Zhang, and J. Baldridge. Mapping natural language instructions to mobile ui\\naction sequences.arXiv preprint arXiv:2005.03776, 2020.\\nY. Liu, K. Shi, K. S. He, L. Ye, A. R. Fabbri, P. Liu, D. Radev, and A. Cohan. On learning to summarize\\nwith large language models as references.arXiv preprint arXiv:2305.14239, 2023.\\nA. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri, S. Prabhumoye,\\nY. Yang, et al. Self-refine: Iterative refinement with self-feedback.Advances in Neural Information\\nProcessing Systems, 36, 2024.\\nO. Nachum, S. S. Gu, H. Lee, and S. Levine. Data-efficient hierarchical reinforcement learning.\\nAdvances in neural information processing systems, 31, 2018.\\nX. Pu, M. Gao, and X. Wan. Summarization is (almost) dead.arXiv preprint arXiv:2309.09558, 2023.\\nM. Reid, N. Savinov, D. Teplyashin, D. Lepikhin, T. Lillicrap, J.-b. Alayrac, R. Soricut, A. Lazaridou,\\nO. Firat, J. Schrittwieser, et al. Gemini 1.5: Unlocking multimodal understanding across millions of\\ntokens of context.arXiv preprint arXiv:2403.05530, 2024.\\nM. Schwarzer, A. Anand, R. Goel, R. D. Hjelm, A. Courville, and P. Bachman. Data-efficient reinforce-\\nment learning with self-predictive representations.arXiv preprint arXiv:2007.05929, 2020.\\nM. Schwarzer, N. Rajkumar, M. Noukhovitch, A. Anand, L. Charlin, R. D. Hjelm, P. Bachman, and\\nA. C. Courville. Pretraining representations for data-efficient reinforcement learning.Advances in\\nNeural Information Processing Systems, 34:12686–12699, 2021.\\nN. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\\nverbal reinforcement learning.Advances in Neural Information Processing Systems, 36, 2024.\\nH. Su, J. Kasai, C. H. Wu, W. Shi, T. Wang, J. Xin, R. Zhang, M. Ostendorf, L. Zettlemoyer, N. A.\\nSmith, et al. Selective annotation makes language models better few-shot learners.arXiv preprint\\narXiv:2209.01975, 2022.\\nC. Team. Codegemma: Open code models based on gemma.arXiv preprint arXiv:2406.11409, 2024a.\\nT. M. A. Team. Codestral: Hello, world!, 2024b. URLhttps://mistral.ai/news/codestral/.\\nP. Thomas and E. Brunskill. Data-efficient off-policy policy evaluation for reinforcement learning. In\\nInternational Conference on Machine Learning, pages 2139–2148. PMLR, 2016.\\nG. Wang, Y. Xie, Y. Jiang, A. Mandlekar, C. Xiao, Y. Zhu, L. Fan, and A. Anandkumar. Voyager: An\\nopen-ended embodied agent with large language models.arXiv preprint arXiv:2305.16291, 2023a.\\nR. Wang, P. Jansen, M.-A. Côté, and P. Ammanabrolu. Scienceworld: Is your agent smarter than a\\n5th grader? arXiv e-prints, pages arXiv–2203, 2022a.\\nX. Wang, Y. Chen, L. Yuan, Y. Zhang, Y. Li, H. Peng, and H. Ji. Executable code actions elicit better\\nllm agents.arXiv preprint arXiv:2402.01030, 2024a.\\nX. Wang, B. Li, Y. Song, F. F. Xu, X. Tang, M. Zhuge, J. Pan, Y. Song, B. Li, J. Singh, H. H. Tran, F. Li,\\nR. Ma, M. Zheng, B. Qian, Y. Shao, N. Muennighoff, Y. Zhang, B. Hui, J. Lin, R. Brennan, H. Peng,\\nH. Ji, and G. Neubig. OpenHands: An Open Platform for AI Software Developers as Generalist\\nAgents, 2024b. URLhttps://arxiv.org/abs/2407.16741.\\n14')]\n"
     ]
    }
   ],
   "source": [
    "resoure = vector_store.similarity_search(\"youtube\", k=3)\n",
    "print(resoure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ede458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI   \n",
    "from langchain_core.output_parsers import StrOutputParser     \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from uuid import uuid4\n",
    "import os\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model='gemini-1.5-flash'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5112aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_txt(file_path:str):\n",
    "    '''Makes json in txt format using ai'''\n",
    "    json_content=[]\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        json_content = file.read()\n",
    "        \n",
    "    response = llm.invoke(f\"You are ai whose job is express json in form of sententes:{json_content}\",)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(response.content)\n",
    "        \n",
    "        \n",
    "    print(\"response\",response.content) \n",
    "      \n",
    "    response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7818cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_to_txt(r\"C://Users//DELL\\Desktop//CloneFlow//production//user_settings//user_info.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b82ffad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def establish_relation():\n",
    "          # Define paths\n",
    "    user_settings = current_dir / 'user_settings' \n",
    "    \n",
    "    files = list((user_settings.glob(\"*\"))) \n",
    "    \n",
    "    print(\"File names in user_settings:\", files)\n",
    "    \n",
    "    uuids = [str(uuid4()) for _ in range(len(files))]  # Generate UUIDs for each file\n",
    "    relationships = {}\n",
    "    for i in range(len(files)):\n",
    "        relationships[files[i].name] =uuids[i]\n",
    "        \n",
    "    print(\"UUIDs:\", uuids)\n",
    "    print(\"Relationships:\", relationships)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1714cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish_relation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c08df3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_dir = Path.cwd()   # ✅ Ensures correct current directory\n",
    "# persist_directory = current_dir / 'db' / 'chroma_db'\n",
    "# user_settings = current_dir / 'user_settings' \n",
    "# files = list((user_settings.glob(\"*\"))) \n",
    "# docslist = []\n",
    "# for f in files:\n",
    "    \n",
    "#         json_to_txt(str(f))  # Convert JSON to text format\n",
    "#         print(f)\n",
    "#         loader = TextLoader(str(f)) \n",
    "#         document = loader.load()\n",
    "#         text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "#         docs = text_splitter.split_documents(document)\n",
    "#         docslist.append(docs)\n",
    "#         print(\"docs\",docs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de8624e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storing_vector_user_settings():\n",
    "    \"\"\"Function to load the vector store from the database.\"\"\"\n",
    "        # Define paths\n",
    "\n",
    "    user_settings = current_dir / 'user_settings' \n",
    "    files = list((user_settings.glob(\"*\"))) \n",
    "    \n",
    "    # relationships = {}\n",
    "    \n",
    "    # # making ids for each file\n",
    "    # ids= [x for x in range(len(files))]\n",
    "    # ids= [str(x) for x in ids]  # Convert to string\n",
    "    \n",
    "    # for i in range(len(files)):\n",
    "    #     relationships[files[i].name] =ids[i]\n",
    "        \n",
    "        \n",
    "    for f in files:\n",
    "        # json_to_txt(str(f))  # Convert JSON to text format\n",
    "        print(f)\n",
    "        loader = TextLoader(str(f)) \n",
    "        document = loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "        docs = text_splitter.split_documents(document)\n",
    "\n",
    "    \n",
    "        if not docs:\n",
    "         print(f\"Split into {len(docs)} chunks, so skipped\")\n",
    "         continue\n",
    "\n",
    "        print(f\"Split into {len(docs)} chunks\")\n",
    "        \n",
    "    \n",
    "        vector_store= Chroma.from_documents(docs, embeddings, persist_directory=str(persist_directory))\n",
    "        \n",
    "    \n",
    " \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aea20c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "user_settings = current_dir / 'user_settings' \n",
    "files = list((user_settings.glob(\"*\"))) \n",
    "    \n",
    "relationships = {}\n",
    "    \n",
    "    # making ids for each file\n",
    "ids= [x for x in range(len(files))]\n",
    "ids= [str(x) for x in ids]  # Convert to string\n",
    "    \n",
    "for i in range(len(files)):\n",
    "     relationships[files[i].name] =ids[i]\n",
    "relationships    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff70b1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95743d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_list():\n",
    "    from itertools import chain\n",
    "    \"\"\"Function to load the vector store from the database.\"\"\"\n",
    "        # Define paths\n",
    "\n",
    "    user_settings = current_dir / 'user_settings' \n",
    "    files = list((user_settings.glob(\"*\"))) \n",
    "    \n",
    "    docslist = []\n",
    "    \n",
    "    for f in files:\n",
    "        # json_to_txt(str(f))  # Convert JSON to text format\n",
    "        print(f)\n",
    "        loader = TextLoader(str(f)) \n",
    "        document = loader.load()\n",
    "        \n",
    "        if not document:\n",
    "            print(f\"Split into {len(document)} chunks, so skipped\")\n",
    "            continue\n",
    "           \n",
    "        if os.path.basename(f) == 'contact.txt':\n",
    "            text_splitter = CharacterTextSplitter(chunk_size=20, chunk_overlap=10)\n",
    "            docs = text_splitter.split_documents(document)\n",
    "            print(\"docs\",docs)\n",
    "            \n",
    "            \n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "        docs = text_splitter.split_documents(document)\n",
    "        docslist.append(docs)\n",
    "        print(\"docs\",docs)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return list(chain.from_iterable(docslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00a234a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33961e14",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected Embedings to be non-empty list or numpy array, got [] in upsert.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:90\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:389\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_upsert_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;129m@validation_context\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mupsert\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_and_prepare_upsert_request\u001b[39m(\n\u001b[32m    375\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    387\u001b[39m ) -> UpsertRequest:\n\u001b[32m    388\u001b[39m     \u001b[38;5;66;03m# Unpack\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     upsert_records = \u001b[43mnormalize_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:187\u001b[39m, in \u001b[36mnormalize_insert_record_set\u001b[39m\u001b[34m(ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03mUnpacks and normalizes the fields of an InsertRecordSet.\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m base_record_set = \u001b[43mnormalize_base_record_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InsertRecordSet(\n\u001b[32m    192\u001b[39m     ids=cast(IDs, maybe_cast_one_to_many(ids)),\n\u001b[32m    193\u001b[39m     metadatas=maybe_cast_one_to_many(metadatas),\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m     uris=base_record_set[\u001b[33m\"\u001b[39m\u001b[33muris\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    198\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:164\u001b[39m, in \u001b[36mnormalize_base_record_set\u001b[39m\u001b[34m(embeddings, documents, images, uris)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03mUnpacks and normalizes the fields of a BaseRecordSet.\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseRecordSet(\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     embeddings=\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    165\u001b[39m     documents=maybe_cast_one_to_many(documents),\n\u001b[32m    166\u001b[39m     images=maybe_cast_one_to_many(images),\n\u001b[32m    167\u001b[39m     uris=maybe_cast_one_to_many(uris),\n\u001b[32m    168\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:61\u001b[39m, in \u001b[36mnormalize_embeddings\u001b[39m\u001b[34m(target)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     62\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected Embedings to be non-empty list or numpy array, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m     )\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# One PyEmbedding\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Expected Embedings to be non-empty list or numpy array, got []",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vector_store= \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1239\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m   1237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1238\u001b[39m     ids = [doc.id \u001b[38;5;28;01mif\u001b[39;00m doc.id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(uuid.uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1192\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m   1187\u001b[39m         api=chroma_collection._client,\n\u001b[32m   1188\u001b[39m         ids=ids,\n\u001b[32m   1189\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1190\u001b[39m         documents=texts,\n\u001b[32m   1191\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1198\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:583\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[38;5;28mself\u001b[39m._collection.upsert(\n\u001b[32m    578\u001b[39m             embeddings=embeddings_without_metadatas,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    579\u001b[39m             documents=texts_without_metadatas,\n\u001b[32m    580\u001b[39m             ids=ids_without_metadatas,\n\u001b[32m    581\u001b[39m         )\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:335\u001b[39m, in \u001b[36mCollection.upsert\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupsert\u001b[39m(\n\u001b[32m    311\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    312\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m    322\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    323\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    324\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[32m    325\u001b[39m \n\u001b[32m    326\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    333\u001b[39m \u001b[33;03m        None\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     upsert_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_upsert_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._upsert(\n\u001b[32m    345\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m    346\u001b[39m         ids=upsert_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    353\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:93\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     92\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg).with_traceback(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:90\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     92\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:389\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_upsert_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;129m@validation_context\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mupsert\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_and_prepare_upsert_request\u001b[39m(\n\u001b[32m    375\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    387\u001b[39m ) -> UpsertRequest:\n\u001b[32m    388\u001b[39m     \u001b[38;5;66;03m# Unpack\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     upsert_records = \u001b[43mnormalize_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m    399\u001b[39m     validate_insert_record_set(record_set=upsert_records)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:187\u001b[39m, in \u001b[36mnormalize_insert_record_set\u001b[39m\u001b[34m(ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnormalize_insert_record_set\u001b[39m(\n\u001b[32m    172\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m    173\u001b[39m     embeddings: Optional[\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    183\u001b[39m ) -> InsertRecordSet:\n\u001b[32m    184\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03m    Unpacks and normalizes the fields of an InsertRecordSet.\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     base_record_set = \u001b[43mnormalize_base_record_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m InsertRecordSet(\n\u001b[32m    192\u001b[39m         ids=cast(IDs, maybe_cast_one_to_many(ids)),\n\u001b[32m    193\u001b[39m         metadatas=maybe_cast_one_to_many(metadatas),\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m         uris=base_record_set[\u001b[33m\"\u001b[39m\u001b[33muris\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    198\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:164\u001b[39m, in \u001b[36mnormalize_base_record_set\u001b[39m\u001b[34m(embeddings, documents, images, uris)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnormalize_base_record_set\u001b[39m(\n\u001b[32m    154\u001b[39m     embeddings: Optional[Union[OneOrMany[Embedding], OneOrMany[PyEmbedding]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    155\u001b[39m     documents: Optional[OneOrMany[Document]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    156\u001b[39m     images: Optional[OneOrMany[Image]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    157\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    158\u001b[39m ) -> BaseRecordSet:\n\u001b[32m    159\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m    Unpacks and normalizes the fields of a BaseRecordSet.\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BaseRecordSet(\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m         embeddings=\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    165\u001b[39m         documents=maybe_cast_one_to_many(documents),\n\u001b[32m    166\u001b[39m         images=maybe_cast_one_to_many(images),\n\u001b[32m    167\u001b[39m         uris=maybe_cast_one_to_many(uris),\n\u001b[32m    168\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\Desktop\\CloneFlow\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:61\u001b[39m, in \u001b[36mnormalize_embeddings\u001b[39m\u001b[34m(target)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     62\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected Embedings to be non-empty list or numpy array, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m     )\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# One PyEmbedding\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target[\u001b[32m0\u001b[39m], (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target[\u001b[32m0\u001b[39m], \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[31mValueError\u001b[39m: Expected Embedings to be non-empty list or numpy array, got [] in upsert."
     ]
    }
   ],
   "source": [
    "vector_store= Chroma.from_documents(docs_list(), embeddings, persist_directory=str(persist_directory),ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e9031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.1}, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='717b530c-4762-4dc4-8cbe-2dd34cb6c2cf', metadata={'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\production\\\\uploads\\\\youtubeinfo.txt'}, page_content='Several YouTube channels have gained massive followings, with T-Series being the most-subscribed channel, followed by MrBeast, Cocomelon, and PewDiePie. The platform has also played a crucial role in launching the careers of content creators, musicians, and influencers.\\n\\nYouTube has faced multiple challenges over the years, including concerns about copyright infringement, misinformation, privacy issues, and content moderation. The company has implemented policies to combat harmful content, including demonetization of inappropriate videos, stricter copyright enforcement through Content ID, and improved moderation using AI and human reviewers.\\n\\nIn addition to its main platform, YouTube offers YouTube Music, a streaming service for music and music videos; YouTube TV, a live TV streaming service offering cable channels; and YouTube Premium, which provides an ad-free experience, offline downloads, and access to exclusive content.'), Document(id='53ed1057-026f-426b-b4fe-2a46073cdccf', metadata={'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\production\\\\uploads\\\\youtubeinfo.txt'}, page_content='Several YouTube channels have gained massive followings, with T-Series being the most-subscribed channel, followed by MrBeast, Cocomelon, and PewDiePie. The platform has also played a crucial role in launching the careers of content creators, musicians, and influencers.\\n\\nYouTube has faced multiple challenges over the years, including concerns about copyright infringement, misinformation, privacy issues, and content moderation. The company has implemented policies to combat harmful content, including demonetization of inappropriate videos, stricter copyright enforcement through Content ID, and improved moderation using AI and human reviewers.\\n\\nIn addition to its main platform, YouTube offers YouTube Music, a streaming service for music and music videos; YouTube TV, a live TV streaming service offering cable channels; and YouTube Premium, which provides an ad-free experience, offline downloads, and access to exclusive content.'), Document(id='f355e39f-b254-4246-923f-1e5bdd321210', metadata={'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\production\\\\uploads\\\\youtubeinfo.txt'}, page_content='Key Features\\nVideo Uploads: Users can upload videos in various formats (MP4, MOV, AVI, etc.).\\nLive Streaming: YouTube supports real-time streaming.\\nMonetization: Through YouTube Partner Program (YPP), creators can earn money via ads, memberships, and Super Chats.\\nYouTube Shorts: A feature for short-form videos (15-60 seconds).\\nYouTube Premium: A subscription service offering ad-free viewing, offline downloads, and background play.\\nStatistics (as of 2024)\\nOver 2.7 billion monthly active users\\nMore than 500 hours of video uploaded every minute\\nAvailable in 100+ countries and 80+ languages\\nContent Categories\\nYouTube covers vlogs, gaming, music, education, tech reviews, tutorials, ASMR, news, etc. Popular YouTubers include MrBeast, PewDiePie, T-Series, and Markiplier.')]\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = retriever.invoke(\"youtube\")\n",
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='aea8993e-4d96-4224-b027-d954f301b0fc', metadata={'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\production\\\\uploads\\\\dataBasePassword.txt'}, page_content='AI Email with Partha      J9wIP7bZWTCSg0L4'), Document(id='d88748d6-fc4c-4ff9-8fed-543653f13fdb', metadata={'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\production\\\\uploads\\\\dataBasePassword.txt'}, page_content='AI Email with Partha      J9wIP7bZWTCSg0L4'), Document(id='1', metadata={'source': 'c:\\\\Users\\\\DELL\\\\Desktop\\\\CloneFlow\\\\production\\\\user_settings\\\\user_info.txt'}, page_content='Partha Kadam, a seventeen-year-old living at 123 Main Street in Springfield, USA, can be reached at partha.kadam@example.com or 123-456-7890.')]\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = retriever.invoke(\n",
    "    '''partha'''\n",
    ")\n",
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9769e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents ---\n",
      "Document 1:\n",
      "AI Email with Partha      J9wIP7bZWTCSg0L4\n",
      "\n",
      "Source: c:\\Users\\DELL\\Desktop\\CloneFlow\\production\\uploads\\dataBasePassword.txt\n",
      "\n",
      "Document 2:\n",
      "AI Email with Partha      J9wIP7bZWTCSg0L4\n",
      "\n",
      "Source: c:\\Users\\DELL\\Desktop\\CloneFlow\\production\\uploads\\dataBasePassword.txt\n",
      "\n",
      "Document 3:\n",
      "Partha Kadam, a seventeen-year-old living at 123 Main Street in Springfield, USA, can be reached at partha.kadam@example.com or 123-456-7890.\n",
      "\n",
      "Source: c:\\Users\\DELL\\Desktop\\CloneFlow\\production\\user_settings\\user_info.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "    if doc.metadata:\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.delete(ids=\"36ce41ef-f62a-480f-8c5d-f6faa1bb48fe\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
